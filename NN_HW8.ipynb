{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-HW8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AUT-Student/NN-HW8/blob/main/NN_HW8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Source"
      ],
      "metadata": {
        "id": "T-mAQ5z06zUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/text/tutorials/transformer"
      ],
      "metadata": {
        "id": "QASm-T5H641U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "aOYz-DDs1Tad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9azbdi0Z-JaB",
        "outputId": "2df3cc79-eae1-4bdf-ee7d-9e04cea98182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.10,>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.9.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (2.9.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (2.9.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (14.0.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.12)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.47.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.26.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfhFyrkP1GzY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text\n",
        "\n",
        "from keras.layers import Dense, Input, Layer, Embedding, Dropout\n",
        "from keras.layers import MultiHeadAttention, LayerNormalization\n",
        "from keras.models import Sequential\n",
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "l2HC-q3w1hGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tfds.load('ted_hrlr_translate/pt_to_en', with_info=False, as_supervised=True)"
      ],
      "metadata": {
        "id": "it2JzZ641fer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]\n",
        "valid_dataset = dataset[\"validation\"]"
      ],
      "metadata": {
        "id": "bNVbC_3I3c-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "vY6qhzM17gLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizers_model_name = 'ted_hrlr_translate_pt_en_converter'\n",
        "keras.utils.get_file(\n",
        "    f'{tokenizers_model_name}.zip',\n",
        "    f'https://storage.googleapis.com/download.tensorflow.org/models/{tokenizers_model_name}.zip',\n",
        "    cache_dir='.', cache_subdir='', extract=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0V3HAL9Q3sSv",
        "outputId": "0b2043ae-4464-4870-cc5d-48c6e4f1281a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./ted_hrlr_translate_pt_en_converter.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizers = tf.saved_model.load(tokenizers_model_name)\n",
        "en_tokenizer = tokenizers.en\n",
        "pt_tokenizer = tokenizers.pt"
      ],
      "metadata": {
        "id": "MVnGQjUt7LoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "LCZi2KfOK2Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_length_list = np.zeros(0)\n",
        "pt_length_list = np.zeros(0)\n",
        "for pt_data, en_data in train_dataset.batch(1024):\n",
        "  new_en_length_list = en_tokenizer.tokenize(en_data).row_lengths().numpy()\n",
        "  new_pt_length_list = pt_tokenizer.tokenize(pt_data).row_lengths().numpy()\n",
        "\n",
        "  en_length_list = np.concatenate((en_length_list, new_en_length_list))\n",
        "  pt_length_list = np.concatenate((pt_length_list, new_pt_length_list))"
      ],
      "metadata": {
        "id": "V4zVq06IAVH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "ax[0].hist(en_length_list, bins=100, color=\"red\", label=\"English\")\n",
        "ax[1].hist(pt_length_list, bins=100, color=\"blue\", label=\"Portuguese\")\n",
        "ax[0].legend()\n",
        "ax[1].legend()\n",
        "ax[0].set_title(\"The Length of English Sentences\")\n",
        "ax[1].set_title(\"The Length of Portuguese Sentences\")\n",
        "ax[0].set_xlabel(\"Length\")\n",
        "ax[1].set_xlabel(\"Length\")\n",
        "ax[0].set_ylabel(\"Frequency\")\n",
        "ax[1].set_ylabel(\"Frequency\")\n",
        "\n",
        "fig.set_size_inches(14, 5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "VNitjzsXkJ-3",
        "outputId": "a5e09535-70d8-43b0-fd1f-32f3fce50366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 128"
      ],
      "metadata": {
        "id": "YZy7fmA-ku9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_size_good(pt, en):\n",
        "  return tf.shape(pt)[1] < MAX_LENGTH and tf.shape(en)[1] < MAX_LENGTH"
      ],
      "metadata": {
        "id": "cvLNtGH42-3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(pt, en):\n",
        "    pt = tokenizers.pt.tokenize(pt)\n",
        "    pt = pt.to_tensor()\n",
        "\n",
        "    en = tokenizers.en.tokenize(en)\n",
        "    en = en.to_tensor()\n",
        "    return pt, en"
      ],
      "metadata": {
        "id": "Q0RMW6z24LGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset_batches(dataset, batch_size):\n",
        "  return dataset.batch(batch_size).map(tokenize, -1).filter(is_size_good).prefetch(-1)"
      ],
      "metadata": {
        "id": "yL84cWKhMZMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataset = create_dataset_batches(train_dataset, batch_size)"
      ],
      "metadata": {
        "id": "0NibEESUMlmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Encoding"
      ],
      "metadata": {
        "id": "NfZYpJ02EG2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(position, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return position * angle_rates"
      ],
      "metadata": {
        "id": "W4nXlgI9egQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "_QVnOc8veI0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking"
      ],
      "metadata": {
        "id": "1v7p7T4kf8C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(sequence):\n",
        "  sequence = tf.cast(tf.math.not_equal(sequence, 0), tf.float32)\n",
        "  mask = sequence[:, tf.newaxis, tf.newaxis, :]\n",
        "  return mask"
      ],
      "metadata": {
        "id": "Dpp-PYzioCt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "GRlvxZNJnzaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer FeedForward"
      ],
      "metadata": {
        "id": "gS3pY3IQNHsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerFeedForward(keras.Model):\n",
        "  def __init__(self, d_feedforward, d_model):\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = Sequential([\n",
        "                             Dense(d_feedforward, activation=\"relu\"),\n",
        "                             Dense(d_model)\n",
        "\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return self.model.call(inputs)"
      ],
      "metadata": {
        "id": "KHV-vDBtNL2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder Block"
      ],
      "metadata": {
        "id": "XpDvgLz8LE2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(Layer):\n",
        "  def __init__(self, d_model, number_heads, d_feedforward):\n",
        "    super().__init__()\n",
        "\n",
        "    self.multi_head_attention = MultiHeadAttention(num_heads=number_heads, key_dim=d_model)\n",
        "    self.feedforward = TransformerFeedForward(d_feedforward=d_feedforward, d_model=d_model)\n",
        "\n",
        "    self.normal_1 = LayerNormalization(epsilon=1e-6)\n",
        "    self.normal_2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout_1 = Dropout(rate=0.1)\n",
        "    self.dropout_2 = Dropout(rate=0.1)\n",
        "\n",
        "  def call(self, x, mask, training):\n",
        "    attention_output = self.multi_head_attention(x, x, x, mask)\n",
        "    dropout_1_output = self.dropout_1(attention_output, training=training)\n",
        "    normal_output = self.normal_1(dropout_1_output + x)\n",
        "\n",
        "    feedforward_output = self.feedforward(normal_output)\n",
        "    dropout_2_output = self.dropout_2(feedforward_output)\n",
        "    output = self.normal_2(dropout_2_output + normal_output) \n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "7z0eecFKDW8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder Block"
      ],
      "metadata": {
        "id": "MQuKbs7kRbAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(Layer):\n",
        "  def __init__(self, number_heads, d_feedforward, d_model):\n",
        "    super().__init__()\n",
        "    self.multi_head_attention_1 = MultiHeadAttention(num_heads=number_heads, key_dim=d_model)\n",
        "    self.multi_head_attention_2 = MultiHeadAttention(num_heads=number_heads, key_dim=d_model)\n",
        "    \n",
        "    self.feedforward = TransformerFeedForward(d_feedforward=d_feedforward, d_model=d_model)\n",
        "\n",
        "    self.normal_1 = LayerNormalization(epsilon=1e-6)\n",
        "    self.normal_2 = LayerNormalization(epsilon=1e-6)\n",
        "    self.normal_3 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout_1 = Dropout(rate=0.1)\n",
        "    self.dropout_2 = Dropout(rate=0.1)    \n",
        "    self.dropout_3 = Dropout(rate=0.1)\n",
        "\n",
        "  def call(self, x, encoder_output, look_ahead_mask, padding_mask, training):    \n",
        "    attention_output_1, attention_weights_1 = self.multi_head_attention_1(\n",
        "        x, x, x, look_ahead_mask, return_attention_scores=True)\n",
        "\n",
        "    dropout_1_output = self.dropout_1(attention_output_1, training=training)\n",
        "    normal_1_output = self.normal_1(dropout_1_output + x)\n",
        "\n",
        "    attention_2_output, attention_weights_2 = self.multi_head_attention_2(\n",
        "        key=encoder_output, value=encoder_output, query=normal_1_output, attention_mask=padding_mask, return_attention_scores=True)\n",
        "    \n",
        "    dropout_2_output = self.dropout_2(attention_2_output, training=training)\n",
        "    normal_2_output = self.normal_2(dropout_2_output + normal_1_output)\n",
        "    \n",
        "    feedforward_output = self.feedforward(normal_2_output)\n",
        "    dropout_3_output = self.dropout_3(feedforward_output, training=training)\n",
        "    normal_3_output = self.normal_3(dropout_3_output + normal_2_output)\n",
        "\n",
        "    return normal_3_output, attention_weights_1, attention_weights_2"
      ],
      "metadata": {
        "id": "1B5daDzvRb0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "lHLbw92Z-39h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Layer):\n",
        "  def __init__(self, number_blocks, d_feedforward, d_model, source_vocab_size,\n",
        "               number_heads):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.embedding = Embedding(source_vocab_size, d_model)\n",
        "    self.number_blocks = number_blocks\n",
        "    self.d_model = d_model\n",
        "\n",
        "    self.pos_encoding = positional_encoding(MAX_LENGTH, self.d_model)\n",
        "    self.dropout = Dropout(rate=0.1)\n",
        "\n",
        "    self.encoder_blocks = []\n",
        "    for _ in range(number_blocks):\n",
        "      self.encoder_blocks.append(EncoderBlock(d_model=d_model, number_heads=number_heads, d_feedforward=d_feedforward))\n",
        "\n",
        "  def call(self, x, mask, training):\n",
        "    sequence_length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "\n",
        "    x += self.pos_encoding[:, :sequence_length, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.number_blocks):\n",
        "      x = self.encoder_blocks[i](x, mask, training)\n",
        "\n",
        "    return x "
      ],
      "metadata": {
        "id": "fq4n4Cdx-8OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "4wQHaQXw-64q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Layer):\n",
        "  def __init__(self, number_blocks, d_feedforward, d_model, number_heads,\n",
        "               target_vocab_size):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.embedding = Embedding(target_vocab_size, d_model)\n",
        "    self.number_blocks = number_blocks\n",
        "    self.d_model = d_model\n",
        "\n",
        "    self.pos_encoding = positional_encoding(MAX_LENGTH, d_model)\n",
        "    self.dropout = Dropout(rate=0.1)\n",
        "\n",
        "    self.decoder_blocks = []\n",
        "    for _ in range(number_blocks):\n",
        "      self.decoder_blocks.append(DecoderBlock(d_model=d_model,\n",
        "                                              number_heads=number_heads,\n",
        "                                              d_feedforward=d_feedforward))\n",
        "\n",
        "  def call(self, x, encoder_output, look_ahead_mask, padding_mask, training):\n",
        "    sequence_length = tf.shape(x)[1]\n",
        "    attention_weights = []\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "\n",
        "    x += self.pos_encoding[:, :sequence_length, :]\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.number_blocks):\n",
        "      x, new_attention_weights_1, new_attention_weights_2 =\\\n",
        "       self.decoder_blocks[i](x=x, encoder_output=encoder_output,\n",
        "                              look_ahead_mask=look_ahead_mask,\n",
        "                              padding_mask=padding_mask, training=training)\n",
        "\n",
        "      attention_weights.append({1:new_attention_weights_1,\n",
        "                                2:new_attention_weights_2})\n",
        "\n",
        "    return x, attention_weights      "
      ],
      "metadata": {
        "id": "yRw8km7WCc0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "SurL2AVE-Czp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(keras.Model):\n",
        "  def __init__(self, number_blocks, number_heads,\n",
        "               d_feedforward, d_model, source_vocab_size,\n",
        "               target_vocab_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = Encoder(number_blocks=number_blocks,\n",
        "                           d_feedforward=d_feedforward, d_model=d_model,\n",
        "                           source_vocab_size=source_vocab_size,\n",
        "                           number_heads=number_heads)\n",
        "\n",
        "    self.decoder = Decoder(number_blocks=number_blocks,\n",
        "                           d_feedforward=d_feedforward, d_model=d_model,\n",
        "                           target_vocab_size=target_vocab_size,\n",
        "                           number_heads=number_heads)\n",
        "\n",
        "    self.last_layer = Dense(target_vocab_size)\n",
        "\n",
        "  def create_masks(self, pt_inputs, en_inputs):\n",
        "    padding_mask = create_padding_mask(pt_inputs)\n",
        "    \n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(en_inputs)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(en_inputs)\n",
        "    look_ahead_mask = tf.minimum(dec_target_padding_mask, look_ahead_mask)\n",
        "    \n",
        "    return padding_mask, look_ahead_mask\n",
        "  \n",
        "  def call(self, inputs, training):\n",
        "    pt_inputs, en_inputs = inputs\n",
        "\n",
        "    padding_mask, look_ahead_mask = self.create_masks(pt_inputs, en_inputs)\n",
        "\n",
        "    encoder_output = self.encoder(pt_inputs, padding_mask, training)\n",
        "\n",
        "    decoder_output, attention_weights = self.decoder(x=en_inputs,\n",
        "                                                     encoder_output=encoder_output,\n",
        "                                                     look_ahead_mask=look_ahead_mask,\n",
        "                                                     padding_mask=padding_mask, training=training)\n",
        "\n",
        "    final_output = self.last_layer(decoder_output)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "metadata": {
        "id": "H6-6TJjP-Acj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "RydZEd08quDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_blocks = 4\n",
        "d_model = 128\n",
        "d_feedforward = 512\n",
        "number_heads = 8\n",
        "number_epochs = 2"
      ],
      "metadata": {
        "id": "3GFJejbtqP1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "qbl67v7VrMUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "metadata": {
        "id": "PrHpz4aErTq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "VUdF7wmrreWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "metadata": {
        "id": "Q0E3ahclrfvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(number_blocks=number_blocks,\n",
        "                          number_heads=number_heads,\n",
        "                          d_feedforward=d_feedforward, d_model=d_model,\n",
        "                          source_vocab_size=pt_tokenizer.get_vocab_size().numpy(),\n",
        "                          target_vocab_size=en_tokenizer.get_vocab_size().numpy())"
      ],
      "metadata": {
        "id": "rGrid86Trhp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(pt_inputs, en_inputs):\n",
        "\n",
        "  en_inputs_input = en_inputs[:, :-1]\n",
        "  en_inputs_real = en_inputs[:, 1:]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = transformer([pt_inputs, en_inputs_input], training=True)[0]\n",
        "    loss = loss_function(en_inputs_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(accuracy_function(en_inputs_real, predictions))"
      ],
      "metadata": {
        "id": "pxvnM_cFuSlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(number_epochs):\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  for (batch, (pt_inputs, en_inputs)) in enumerate(train_dataset):\n",
        "    train_step(pt_inputs, en_inputs)\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      accuracy_percent = train_accuracy.result().numpy()*100\n",
        "      loss_result = train_loss.result().numpy()\n",
        "      print(f\"Epoch {epoch+1} Batch {batch} -> Loss = {loss_result:.2f}, Accuracy {round(accuracy_percent,2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10bKnpxasPVm",
        "outputId": "dec1221b-7418-4d59-9c71-98ae0ef12290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 -> Loss = 8.85, Accuracy 0.0%\n",
            "Epoch 1 Batch 100 -> Loss = 8.66, Accuracy 2.73%\n",
            "Epoch 1 Batch 200 -> Loss = 8.40, Accuracy 4.04%\n",
            "Epoch 1 Batch 300 -> Loss = 8.03, Accuracy 5.61%\n",
            "Epoch 1 Batch 400 -> Loss = 7.64, Accuracy 6.63%\n",
            "Epoch 1 Batch 500 -> Loss = 7.32, Accuracy 8.43%\n",
            "Epoch 1 Batch 600 -> Loss = 7.05, Accuracy 10.17%\n",
            "Epoch 1 Batch 700 -> Loss = 6.81, Accuracy 11.68%\n",
            "Epoch 2 Batch 0 -> Loss = 5.28, Accuracy 22.41%\n",
            "Epoch 2 Batch 100 -> Loss = 5.16, Accuracy 23.46%\n",
            "Epoch 2 Batch 200 -> Loss = 5.09, Accuracy 24.39%\n",
            "Epoch 2 Batch 300 -> Loss = 5.01, Accuracy 25.31%\n",
            "Epoch 2 Batch 400 -> Loss = 4.93, Accuracy 26.07%\n",
            "Epoch 2 Batch 500 -> Loss = 4.86, Accuracy 26.77%\n",
            "Epoch 2 Batch 600 -> Loss = 4.80, Accuracy 27.46%\n",
            "Epoch 2 Batch 700 -> Loss = 4.74, Accuracy 28.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translator"
      ],
      "metadata": {
        "id": "1l6M3rLRGw3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(keras.Model):\n",
        "  def __init__(self, transformer, en_tokenizer, pt_tokenizer):\n",
        "    super().__init__()\n",
        "\n",
        "    self.transformer = transformer\n",
        "    self.en_tokenizer = en_tokenizer\n",
        "    self.pt_tokenizer = pt_tokenizer\n",
        "\n",
        "  def translate(self, sentence):\n",
        "    pt_tokens = self.pt_tokenizer.tokenize(tf.expand_dims(sentence, axis=0)).to_tensor()\n",
        "\n",
        "    start_token, end_token = self.en_tokenizer.tokenize([''])[0]\n",
        "    start_token = start_token[tf.newaxis]\n",
        "    end_token = end_token[tf.newaxis]\n",
        "\n",
        "    en_tokens = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    en_tokens = en_tokens.write(0, start_token)\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "      en_tokens_transpose = tf.transpose(en_tokens.stack())\n",
        "\n",
        "      predictions, _ = self.transformer([pt_tokens, en_tokens_transpose], training=False)\n",
        "\n",
        "      predictions = predictions[:, -1:, :]\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      en_tokens = en_tokens.write(i+1, predicted_id[0])\n",
        "\n",
        "      if predicted_id == end_token:\n",
        "        break\n",
        "\n",
        "    en_tokens_transpose = tf.transpose(en_tokens.stack())\n",
        "\n",
        "    text = en_tokenizer.detokenize(en_tokens_transpose)[0]\n",
        "\n",
        "    tokens = en_tokenizer.lookup(en_tokens_transpose)[0]\n",
        "\n",
        "    attention_weights = self.transformer([pt_tokens, en_tokens_transpose[:,:-1]], training=False)[1]\n",
        "\n",
        "    return text, tokens, attention_weights"
      ],
      "metadata": {
        "id": "lv2XTQUq7ny3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(transformer=transformer,\n",
        "                        en_tokenizer=en_tokenizer, pt_tokenizer=pt_tokenizer)"
      ],
      "metadata": {
        "id": "L5k9HVm8Tl9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Examples"
      ],
      "metadata": {
        "id": "COBscKNNRuPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for test_example in test_dataset.take(10):\n",
        "  pt_text = test_example[0].numpy()\n",
        "  en_text = test_example[1].numpy()\n",
        "  en_predicted_text = translator.translate(pt_text)[0]\n",
        "\n",
        "  print(f\"Portuguese Input Text  = {pt_text}\")\n",
        "  print(f\"English Real Text      = {en_text}\")\n",
        "  print(f\"English Predicted Text = {en_predicted_text.numpy()}\\n\")\n"
      ],
      "metadata": {
        "id": "NYm1jWcrRwCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1bd08b2-f22e-411c-bf44-a95fa86595b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Portuguese Input Text  = b'depois , podem fazer-se e testar-se previs\\xc3\\xb5es .'\n",
            "English Real Text      = b'then , predictions can be made and tested .'\n",
            "English Predicted Text = b'and you can do it and be a lot of it .'\n",
            "\n",
            "\n",
            "Portuguese Input Text  = b'for\\xc3\\xa7ou a parar m\\xc3\\xbaltiplos laborat\\xc3\\xb3rios que ofereciam testes brca .'\n",
            "English Real Text      = b'it had forced multiple labs that were offering brca testing to stop .'\n",
            "English Predicted Text = b'the other people have been able to be able to be a lot of the tra'\n",
            "\n",
            "\n",
            "Portuguese Input Text  = b'as formigas s\\xc3\\xa3o um exemplo cl\\xc3\\xa1ssico ; as oper\\xc3\\xa1rias trabalham para as rainhas e vice-versa .'\n",
            "English Real Text      = b'ants are a classic example ; workers work for queens and queens work for workers .'\n",
            "English Predicted Text = b'the srops are a new years of the other - spppppp .'\n",
            "\n",
            "\n",
            "Portuguese Input Text  = b'uma em cada cem crian\\xc3\\xa7as no mundo nascem com uma doen\\xc3\\xa7a card\\xc3\\xadaca .'\n",
            "English Real Text      = b'one of every hundred children born worldwide has some kind of heart disease .'\n",
            "English Predicted Text = b'a world in the world in the world in the world with a new world'\n",
            "\n",
            "\n",
            "Portuguese Input Text  = b'neste momento da sua vida , ela est\\xc3\\xa1 a sofrer de sida no seu expoente m\\xc3\\xa1ximo e tinha pneumonia .'\n",
            "English Real Text      = b\"at this point in her life , she 's suffering with full-blown aids and had pneumonia .\"\n",
            "English Predicted Text = b'in this world of the world , the first is the sraproppppp .'\n",
            "\n",
            "\n",
            "Portuguese Input Text  = b'onde est\\xc3\\xa3o as redes econ\\xc3\\xb3micas ?'\n",
            "English Real Text      = b'where are economic networks ?'\n",
            "English Predicted Text = b'what are the other people ?'\n",
            "\n",
            "\n",
            "Portuguese Input Text  = b'( aplausos )'\n",
            "English Real Text      = b'( applause )'\n",
            "English Predicted Text = b'( applause )'\n",
            "\n",
            "\n",
            "Portuguese Input Text  = b'eu usei os contentores de transporte , e tamb\\xc3\\xa9m os alunos ajudaram-nos a fazer toda a mob\\xc3\\xadlia dos edif\\xc3\\xadcios , para torn\\xc3\\xa1-los confort\\xc3\\xa1veis\\xe2\\x80\\x8b\\xe2\\x80\\x8b , dentro do or\\xc3\\xa7amento do governo , mas tamb\\xc3\\xa9m com a mesma a \\xc3\\xa1rea da casa , mas muito mais confort\\xc3\\xa1vel .'\n",
            "English Real Text      = b'i used the shipping container and also the students helped us to make all the building furniture to make them comfortable , within the budget of the government but also the area of the house is exactly the same , but much more comfortable .'\n",
            "English Predicted Text = b\"i ' m going to the same , and the same , and the other people have to be able to be the world , and the world , but the world , but the world , but it ' s the world , but it has been able to be able to\"\n",
            "\n",
            "\n",
            "Portuguese Input Text  = b'e , no entanto , a ironia \\xc3\\xa9 que a \\xc3\\xbanica maneira de podermos fazer qualquer coisa nova \\xc3\\xa9 dar um passo nessa dire\\xc3\\xa7\\xc3\\xa3o .'\n",
            "English Real Text      = b'and yet , the irony is , the only way we can ever do anything new is to step into that space .'\n",
            "English Predicted Text = b'and in the world , the world is the way to do that we do is a lot of the way .'\n",
            "\n",
            "\n",
            "Portuguese Input Text  = b'a luz nunca desaparece .'\n",
            "English Real Text      = b'the light never goes out .'\n",
            "English Predicted Text = b'the first was going to be .'\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_text = \"os meus vizinhos ouviram sobre esta ideia.\"\n",
        "input_text = \"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\"\n",
        "# input_text = \"este é um problema que temos que resolver.\"\n",
        "\n",
        "text, tokens, attention_weight = translator.translate(tf.constant(input_text))\n",
        "\n",
        "print(text.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oftWHfBGUpH5",
        "outputId": "bc592f6c-77bb-44a8-dfa2-f3280cc47165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"i ' m going to see a lot of you can be a lot of people that we ' re\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Weights"
      ],
      "metadata": {
        "id": "TRxCwC6-Bkd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weight = tf.squeeze(attention_weight[-1][2]).numpy()"
      ],
      "metadata": {
        "id": "NF6zDfVomHiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weight.shape[0]"
      ],
      "metadata": {
        "id": "ZaCDkYuxA6Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weight_heads = []\n",
        "\n",
        "for i in range(attention_weight.shape[0]):\n",
        "  attention_weight_heads.append(attention_weight[i])"
      ],
      "metadata": {
        "id": "Ikd7R7YkmxGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(4, 2)\n",
        "pt_tokens = pt_tokenizer.tokenize([input_text]).numpy()[0]\n",
        "pt_tokens = pt_tokenizer.lookup([pt_tokens]).numpy()[0]\n",
        "\n",
        "en_tokens = en_tokenizer.tokenize([text]).numpy()[0]\n",
        "en_tokens = en_tokenizer.lookup([en_tokens]).numpy()[0]\n",
        "\n",
        "for i in range(8):\n",
        "  ax[i//2][i%2].matshow(attention_weight_heads[i], cmap=\"YlOrBr\")\n",
        "  ax[i//2][i%2].set_xticks(range(len(pt_tokens)))\n",
        "  ax[i//2][i%2].set_xticklabels(pt_tokens, rotation=90)\n",
        "\n",
        "  ax[i//2][i%2].set_yticks(range(len(en_tokens)))\n",
        "  ax[i//2][i%2].set_yticklabels(en_tokens)\n",
        "\n",
        "  \n",
        "\n",
        "fig.set_size_inches((12, 25))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k1N4QdpFCBR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZgWaeX3qB67J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}