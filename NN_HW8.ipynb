{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-HW8.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNC1zhAOSe3RSgLVbCI6QAh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AUT-Student/NN-HW8/blob/main/NN_HW8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Source"
      ],
      "metadata": {
        "id": "T-mAQ5z06zUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/text/tutorials/transformer"
      ],
      "metadata": {
        "id": "QASm-T5H641U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "aOYz-DDs1Tad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text\n",
        "!pip install tensorflow-probability"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9azbdi0Z-JaB",
        "outputId": "90004fff-c3aa-4c7b-9a39-479ee3ae82ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Requirement already satisfied: tensorflow<2.10,>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (4.1.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.12)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (14.0.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (2.9.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.47.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (2.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (2.9.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (0.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (0.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (0.1.7)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GfhFyrkP1GzY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow_text\n",
        "\n",
        "from keras.layers import Dense, Input, MultiHeadAttention, LayerNormalization, Layer, Embedding\n",
        "from keras.models import Sequential\n",
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "l2HC-q3w1hGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tfds.load('ted_hrlr_translate/pt_to_en', with_info=False, as_supervised=True)"
      ],
      "metadata": {
        "id": "it2JzZ641fer"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]\n",
        "valid_dataset = dataset[\"validation\"]"
      ],
      "metadata": {
        "id": "bNVbC_3I3c-t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "vY6qhzM17gLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizers_model_name = 'ted_hrlr_translate_pt_en_converter'\n",
        "keras.utils.get_file(\n",
        "    f'{tokenizers_model_name}.zip',\n",
        "    f'https://storage.googleapis.com/download.tensorflow.org/models/{tokenizers_model_name}.zip',\n",
        "    cache_dir='.', cache_subdir='', extract=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0V3HAL9Q3sSv",
        "outputId": "3d62490f-0555-4cc5-cb7d-73abfbbd2fbf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./ted_hrlr_translate_pt_en_converter.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizers = tf.saved_model.load(tokenizers_model_name)\n",
        "en_tokenizer = tokenizers.en\n",
        "pt_tokenizer = tokenizers.pt"
      ],
      "metadata": {
        "id": "MVnGQjUt7LoF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batching"
      ],
      "metadata": {
        "id": "LCZi2KfOK2Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_length_list = np.zeros(0)\n",
        "pt_length_list = np.zeros(0)\n",
        "for pt_data, en_data in train_dataset.batch(4*1024):\n",
        "  new_en_length_list = en_tokenizer.tokenize(en_data).row_lengths().numpy()\n",
        "  new_pt_length_list = pt_tokenizer.tokenize(pt_data).row_lengths().numpy()\n",
        "\n",
        "  en_length_list = np.concatenate((en_length_list, new_en_length_list))\n",
        "  pt_length_list = np.concatenate((pt_length_list, new_pt_length_list))"
      ],
      "metadata": {
        "id": "V4zVq06IAVH6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "ax[0].hist(en_length_list, bins=100, color=\"red\", label=\"English\")\n",
        "ax[1].hist(pt_length_list, bins=100, color=\"blue\", label=\"Portuguese\")\n",
        "ax[0].legend()\n",
        "ax[1].legend()\n",
        "ax[0].set_title(\"The Length of English Sentences\")\n",
        "ax[1].set_title(\"The Length of Portuguese Sentences\")\n",
        "ax[0].set_xlabel(\"Length\")\n",
        "ax[1].set_xlabel(\"Length\")\n",
        "ax[0].set_ylabel(\"Frequency\")\n",
        "ax[1].set_ylabel(\"Frequency\")\n",
        "\n",
        "fig.set_size_inches(14, 5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "VNitjzsXkJ-3",
        "outputId": "f301c123-0b3f-4bd8-bf83-eebe3aa77077"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x360 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA00AAAFNCAYAAADcnIQFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxdZXno8d8jU0CQMReBIAFNUYYQYpgu6kWUsUqoCmKtRmWwFlu91lZovSYOWLzXaqVaEAoarMqkKCpWBqUOFSGEgBCURMYgQ0iY58Bz/1jvCTuHs9fZZ9hnn73P7/v5rM9Z613Dft+9dvaT513vWjsyE0mSJEnSwF7U6QpIkiRJ0nhm0iRJkiRJNUyaJEmSJKmGSZMkSZIk1TBpkiRJkqQaJk2SJEmSVMOkSUMSEfMi4j86XY/RFBG3RcQbR+lYfxYRd0bEoxGx+2gcs8XX3S8iljUs3xgR+w2yz9SIyIhYu+0VlKRhMu4MeqyOxB1pojFp0hrKl27f9FxEPNGw/M5Rfq2vR8RnRvOY4+A1Pw98MDM3zMxrB3j9jIjH+r3Pfz/alcjMnTPzitE8ZkRMiYjvRMT9EfFQRNwQEe8ZheOavEkTmHFnxIYSd+6KiC9ExFrDeaFyrFeMuMbjRESsGxH/HBHLyvtzW0T8yygde9QSY40P/idFa8jMDfvmI+I24JjMvKyhbF4HqtVNtgNuHGSb3TJz6VhUZpR9A7iOqo1PAbsCL+1ojSR1PePOiLUcdyLilcAVwM3Aaa2+QESsnZmrhl/FcetEYBawJ3A31Xv5uo7WSOOWV5o0HOtGxNkR8UgZBjarb0VEbF2uRiyPiFsj4m+G8wIR8aaIWBQRD0bEf0fE9IZ1t0XERyPi+nLF49yImNSw/u8j4u6I+GNEHNPXMxYRxwHvBP6+9Cj9oOElZzQ7Xr96vSgiPh4Rt0fEfeV92Dgi1ouIR4G1gOsi4g/DaPO8iDiv5r2dGRHXlnXnl3oO2HvZ2MMVEXtGxIKIeDgi7o2IL/Tb/J0RcUe5gvSPNVXcA/h6Zj6Wmasy89rM/HHDa+5dztWDEXFdNAwPjIgrIuLTEfGrUv9LImKLsvrn5e+D5bzsU/Z5X0TcFBEPRMRPImK7huNlRPxlRCwpr/eViIiG9ceWfR+JiMURMbOUN/18tvA+Seoc484oxJ3M/B3wC2CXcuxjI2JpRKyMiIsiYuuG182IOD4ilgBLIqLvu/q60pa3R8R7IuKX/eq7+mpURGweET8o36tXR8Rn+raPAUYZlFhxTMPygHEgKl8s78fDEfHbiOhr03oR8fkS1+6NiNMiYv0mb8kewIWZ+ces3JaZZze8fl3MaBqzI+IbwMuAH0TDiJIYfpwkIl7TsO+dUUZ61LU3IraIiB+WfVZGxC8iwv/7D1dmOjkNOAG3AW/sVzYPeBI4lOqL+p+AK8u6FwHXAJ8A1gV2AG4BDmpy/K8DnxmgfHfgPmCv8hpzSl3Wa6jXVcDWwGbATcBflnUHA/cAOwMbAP8BJPCKZq9Zd7wB6vY+YGlp24bAd4FvNKxf/VpN9m+6fpD3dl3gduBDwDrAW4Cn+9oC7AcsG+jcAb8G3lXmNwT2LvNTS33OANYHdqO6gvSqJvW7DPgVcBTwsn7rtgFWlLq/CDigLE8u668A/gD8SXmtK4CT+9Vj7YbjzS7v86uoroh/HPjvfu/jD4FNqALTcuDgsu4I4C6qYBjAK6h6D2s/n83eJycnp7GbMO4MVOdRizvATqWuRwP7A/cDM4H1gH8Fft5vv0tL/dYf6LWA9wC/rHm9c8q0QXntO/u2Z+Dv/iuorjRCTRwADirnfROq7/lXAVuVdV8ELir13gj4AfBPTd6bjwN3AH9FNXoiGtYNFjPm0eRzOdBnmZHFye2AR4B3UP0fYHNgxmDtLXU6reyzDvDaxjY6DW0y29Rw/DIzL87MZ6mGbO1Wyveg+sf/qcx8OjNvofoP+VFDPP5xwFcz8zeZ+Wxmzqf6z/zeDducklXP0EqqL4gZpfxI4GuZeWNmPk71pdaKZsfr753AFzLzlsx8lOrS/lExtPtxFpZen77poIZ1zd7bvamCximZ+Uxmfpcq4LbiGeAVEbFFZj6amVf2W//JzHwiM6+jGn632wsPAVTJyC+A/wPcWnpk9yjr/gK4uNT9ucy8FFhAFRz6fC0zb87MJ4DzaP4eA/wl1Zf+TVkNCfksVa/sdg3bnJyZD2bmHcDPGo53DPB/M/PqrCzNzNsZ/PM52PskqXOMOyOPOw+U1/l34GvluGdl5sLMfKocd5+ImNqw3z9l5sryvT0kUd039VZgbmY+npmLgflDOERdHHiGKkF4JVUScFNm3h0RQXUu/3ep9yNlv2afh38CPkf1XiwA7oqIOWVdK5+tZp/LgYwkTv45cFlmfrv8H2BFZi5qob3PAFsB25X9fpFZZVMaOpMmDcc9DfOPA5PKl/d2wNaNCQHwD8CWQzz+dsDf9jvOtlQ9cs3q0Dcmfmuqnqw+jfN1mh2vv62prvj0uZ0qmRlKG2dm5iYN009q6tH33m4N3NXvy67Vth1N1XP1uzI84k391rfU9sx8IDNPyMydqdq7CPhe+dLeDjii3zl7DdWX9ZBep9gO+FLDsVZS9SZu08LxtqXqrRvomHWfz8HeJ0mdY9x53nDjzqaZ+fLM/HhmPtf/uCUhW8Ga37OttmUgk0s9h/PeQE0cyMyfAl8GvgLcFxGnR8RLymtuAFzTsN9/lvIXKAnyVzJzX6qrVicBZ0XEq2jts9Xsc9msPcONk83i2mDt/X9UV+suiYhbIuKEJnVTC3wQhEbTncCtmTltFI5zUmaeNIx97wamNCxv22/9SHtY/kj1xdfnZcAq4N4RHncwdwPbREQ0JE7NvkTXkJlLgHeUccxvAS6IiM1HUpnMvD8iPk81hGUzqnP2jcw8djiHG6Cs7zPwzWEc707g5U3Km34+m71PmfnYMOogaWwYd0bpuBHxYqphX3c1bDNY3R+j+k973zEaHw60vNRzCtWDJ2DN96bvu3UD4OEy37h/bRzIzFOAUyLif1Bdlfk7YC7wBLBzZt410H7NlKs7X4mIT/L8UMKRfLb6v3cjiZN3Uj2sor/7qWlvufL0t1QdArsAP42IqzPz8mHUYcLzSpNG01XAIxHxsYhYPyLWiohdGoZwDWStiJjUMK1Ldfn7LyNir6i8OCL+NCI2aqEO5wHvjYhXRcQGVEPJGt1LNS55uL4N/O+I2D4iNqS6DH5utv+pQr8GngU+GBFrR8RsBv4CfYGI+IuImFx6Fh8sxc8NtQIR8blyPtcu5+IDwNLMXEE1hv/NEXFQOe+TovrtqCn1RwWqwPoca56X04ATI2Ln8tobR8QRLVb134GPRsSry+fnFWU4R+3nc7TeJ0ljyrgzsuO+NyJmRMR65bi/yczbavbp35brgJ3LMSbRMDSxDFn7LjAvIjaI6sl9725Yv5wqQfuLct7ex5odXk3jQETsUc7VOlTJ15PAc+X7+wzgiyWZIiK2iTWHwa8WER8usWr9EtvmUA37u5bhfbbq3quRxMlvAm+MiCNLPTePiBmDtTeqh5u8IiICeIjq/xHGtWEyadKoKV+Qb6Iag3srVQ/IvwMb1+x2AlUvSd/008xcABxLden9AapLy+9psQ4/Bk6husdlKdB3X8pT5e+ZwE5RXcb+Xqtta3AW1bjln1O18Ungr4d4jL4nD/VNg/4mRGY+TXX142iq/9D/BdWDEJ6q2684GLgxqqcsfQk4ajjj06l6Ay8sr38LVQ/lYaV+d1LdtPsPVEnQnVS9foN+x5R7AE4CflXOy96ZeSHVOPNzIuJh4AbgkFYqmZnnl+N9i+rG2e8Bm7Xw+Ryt90nSGDHuDF9Wj3X/P8B3qK6WvZzB7wWbB8wvbTkyM28GPkX1oKAlwC/7bf9BqnNxT2nDt1kzbh1LFStWUD1I478b6lcXB15ClSw8QDXEcAXVUDSAj1HOQ9nvMmDHJu15HPjnUr/7geOBt5b7x4bz2Wr0T8DHy3v10RHGyTuo7n36W6phiot4/v6puvZOK8uPUnW+/ltm/qzF+quf8H4w9bKoxiXfQPUEpJ76jYmI+A1wWmZ+rdN1kSRVejnujFREfA54aWbOGXRjaZzxSpN6TkT8WVS/W7ApVS/VD3ohcEXE/4qIlzYMIZhOdcOnJKmDejXujFREvDIippchj3tSjZa4sNP1kobDpEm96P1Uv7fxB6rxux/obHVGzY5U48cfpLpE/7bMvLuzVZIk0btxZ6Q2orqv6THgXKqhcN/vaI2kYXJ4niRJkiTV8EqTJEmSJNUwaZIkSZKkGj3547ZbbLFFTp06tdPVkKQJ7Zprrrk/MycPvuXEY5ySpPGh1VjVk0nT1KlTWbBgQaerIUkTWkTc3uk6jFfGKUkaH1qNVQ7PkyRJkqQaJk2SJEmSVMOkSZI0IUXEjhGxqGF6OCI+HBGbRcSlEbGk/N20bB8RcUpELI2I6yNiZsOx5pTtl5Qfn5Yk9ZCevKdJkkbbM888w7Jly3jyySc7XZVxZ9KkSUyZMoV11lmn01UZksz8PTADICLWAu4CLgROAC7PzJMj4oSy/DHgEGBamfYCTgX2iojNgLnALCCBayLiosx8YIybJKmLGFfG1khjVduSpojYkerXn/vsAHwCOLuUTwVuA47MzAciIoAvAYcCjwPvycyF5VhzgI+X43wmM+e3q96SNJBly5ax0UYbMXXqVKqvKwFkJitWrGDZsmVsv/32na7OSLwB+ENm3h4Rs4H9Svl84AqqpGk2cHZWvwp/ZURsEhFblW0vzcyVABFxKXAw8O0xbYGkrmJcGTujEavaNjwvM3+fmTMycwbwaqpEqLEHbxpweVmGNXvwjqPqwaOhB28vYE9gbt9QCUkaK08++SSbb765ga2fiGDzzTfvhZ7So3g+ydkyM+8u8/cAW5b5bYA7G/ZZVsqalUtSU8aVsTMasWqs7mla3YNH1VPXd6VoPnB4mV/dg5eZVwJ9PXgHUXrwylCHvh48SRpTBraBdfv7EhHrAocB5/dfV64q5Si9znERsSAiFixfvnw0Dimpy3X792c3Gel7PVZJkz14kjRCa621FjNmzFg9nXzyycM+1oYbbgjAH//4R972trc13e62225jl112GfbrdIlDgIWZeW9Zvrd02lH+3lfK7wK2bdhvSilrVr6GzDw9M2dl5qzJk/3NX0md1xdXdtllF4444ggef/zxlvddtGgRF198cRtrN760PWmyB09ST4oY3akF66+/PosWLVo9nXDCCYPvNIitt96aCy64YMTH6XLvYM37jy4C+p6ANwf4fkP5u8tT9PYGHiqdgD8BDoyITcvw8QNLmSS1rANhZXVcueGGG1h33XU57bTTWtpv1apVJk1tYA+eJLXR1KlTmTt3LjNnzmTXXXfld7/7HQDLly/ngAMOYOedd+aYY45hu+224/77719j38YrSTfeeCN77rknM2bMYPr06SxZsgSAZ599lmOPPZadd96ZAw88kCeeeGJsG9hGEfFi4ADguw3FJwMHRMQS4I1lGeBi4BZgKXAG8FcA5QEQnwauLtOn+h4KIUnd4rWvfS1Lly5l5cqVHH744UyfPp29996b66+/HoB58+bxrne9i3333Zd3vetdfOITn+Dcc89lxowZnHvuucybN4/Pf/7zq4+3yy67cNtttwHw6U9/mh133JHXvOY1vOMd71i93X777ceCBQsAuP/++5k6dSpQxZ2/+7u/Y4899mD69Ol89atfBeDuu+/mda973eqrY7/4xS8AuOSSS9hnn32YOXMmRxxxBI8++uiovz9jkTTZgydJo+CJJ55YY3jeuec+/4DSLbbYgoULF/KBD3xgdTD65Cc/yf7778+NN97I2972Nu64447a45922ml86EMfYtGiRSxYsIApU6YAsGTJEo4//nhuvPFGNtlkE77zne+0r5FjLDMfy8zNM/OhhrIVmfmGzJyWmW/sS4DKPbfHZ+bLM3PXzFzQsM9ZmfmKMn2tE22RpOFatWoVP/7xj9l1112ZO3cuu+++O9dffz2f/exnefe73716u8WLF3PZZZfx7W9/m0996lO8/e1vZ9GiRbz97W9veuyrr76a73znO1x33XX8+Mc/Xp0k1TnzzDPZeOONufrqq7n66qs544wzuPXWW/nWt77FQQcdxKJFi7juuuuYMWMG999/P5/5zGe47LLLWLhwIbNmzeILX/jCqLwvjdr6O00NPXjvbyg+GTgvIo4GbgeOLOUXUz1ufCnVk/beC1UPXkT09eBBp3vwGq935qiMLJSklvQNoxjIW97yFgBe/epX893vVhdNfvnLX3LhhRcCcPDBB7PppvUPHt1nn3046aSTWLZsGW95y1uYNm0aANtvvz0zZsxYffy+nkONf4YsSXX6OuOgutJ09NFHs9dee63uHNt///1ZsWIFDz/8MACHHXYY66+//pBe41e/+hWzZ89m0qRJTJo0iTe/+c2D7nPJJZdw/fXXrx4+/tBDD7FkyRL22GMP3ve+9/HMM89w+OGHM2PGDP7rv/6LxYsXs++++wLw9NNPs88++wypjq1oa9KUmY8Bm/crW0H1NL3+2yZwfJPjnAWc1Y46SlIvWG+99YDqpt5Vq1YN6xh//ud/zl577cWPfvQjDj30UL761a+yww47rD523/F7aXieJE1kdZ1xA3nxi1/cdN3aa6/Nc889t3q5lcd7N+7TuH1m8q//+q8cdNBBL9jn5z//OT/60Y94z3vew0c+8hE23XRTDjjgAL797fb+NN5YPT1PkjTG9t13X8477zyg6rV74IEHare/5ZZb2GGHHfibv/kbZs+evXocuyRp4njta1/LN7/5TQCuuOIKtthiC17ykpe8YLuNNtqIRx55ZPXy1KlTWbhwIQALFy7k1ltvBapY9IMf/IAnn3ySRx99lB/+8Idr7HPNNdcArPFQooMOOohTTz2VZ555BoCbb76Zxx57jNtvv50tt9ySY489lmOOOYaFCxey995786tf/YqlS5cC8Nhjj3HzzTeP5lsCmDRJUtfof0/TYE/Pmzt3Lpdccgm77LIL559/Pi996UvZaKONmm5/3nnnscsuuzBjxgxuuOGGNcaxS5Imhnnz5nHNNdcwffp0TjjhBObPnz/gdq9//etZvHjx6nts3/rWt7Jy5Up23nlnvvzlL/Mnf/InAOyxxx4cdthhTJ8+nUMOOYRdd92VjTfeGICPfvSjnHrqqey+++5rPKjomGOOYaeddmLmzJnssssuvP/972fVqlVcccUV7Lbbbuy+++6ce+65fOhDH2Ly5Ml8/etf5x3veAfTp09nn332Wf1ApNEU2YODnGfNmpWt3GQ2LM2e4diD76Ok591000286lWv6nQ1huSpp55irbXWYu211+bXv/41H/jAB4Y0DGMoBnp/IuKazJzVlhfscm2NUw28p0kav7oxrgzXo48+yoYbbsjjjz/O6173Ok4//XRmzpw55vUYSaxq6z1NkqTOueOOOzjyyCN57rnnWHfddTnjjDM6XSVJ0gR03HHHsXjxYp588knmzJnTkYRppEyaJKlHTZs2jWuvvbbT1ZAkTXDf+ta3Ol2FEfOeJkmSJEmqYdIkSS3qxXtAR4PviyQNj9+fY2ek77VJkyS1YNKkSaxYscIA109msmLFCiZNmtTpqkhSVzGujJ3RiFXe0yRJLZgyZQrLli1j+fLlna7KuDNp0iSmTJnS6WpIUlcxroytkcYqkyZJasE666zD9ttv3+lqSINq9ssYksYX40p3cXieJEmSJNUwaZIkSZKkGiZNkiRJklTDpEmSJEmSapg0SZIkSVINkyZJkiRJqmHSJEmSJEk1TJokSZIkqYZJkyRJkiTVMGmSJEmSpBomTZIkSZJUw6RJkiRJkmqYNEmSJElSDZMmSZIkSaph0iRJkiRJNUyaJEmSJKmGSZMkSZIk1TBpkiRNWBGxSURcEBG/i4ibImKfiNgsIi6NiCXl76Zl24iIUyJiaURcHxEzG44zp2y/JCLmdK5FkqR2MGmSJE1kXwL+MzNfCewG3AScAFyemdOAy8sywCHAtDIdB5wKEBGbAXOBvYA9gbl9iZYkqTe0NWmyB0+SNF5FxMbA64AzATLz6cx8EJgNzC+bzQcOL/OzgbOzciWwSURsBRwEXJqZKzPzAeBS4OAxbIokqc3afaXJHjxJ0ni1PbAc+FpEXBsR/x4RLwa2zMy7yzb3AFuW+W2AOxv2X1bKmpVLknpE25Ime/AkSePc2sBM4NTM3B14jOc78gDIzARyNF4sIo6LiAURsWD58uWjcUhJ0hhp55Ume/AkSePZMmBZZv6mLF9AlUTdWzrtKH/vK+vvArZt2H9KKWtWvobMPD0zZ2XmrMmTJ49qQyRJ7dXOpMkePEnSuJWZ9wB3RsSOpegNwGLgIqDv/tk5wPfL/EXAu8s9uHsDD5VOwJ8AB0bEpmX4+IGlbFyJWHOSJLVu7TYee6AevBMoPXiZefcQevD261d+Rf8Xy8zTgdMBZs2aNSqJmCSp5/018M2IWBe4BXgvVYfieRFxNHA7cGTZ9mLgUGAp8HjZlsxcGRGfBq4u230qM1eOXRMkSe3WtqQpM++JiDsjYsfM/D3P9+Atpuq5O5kX9uB9MCLOoXrow0MlsfoJ8NmGhz8cCJzYrnpLkiaOzFwEzBpg1RsG2DaB45sc5yzgrNGtnSRpvGjnlSawB0+SJElSl2tr0mQPniRJkqRu1+7faZIkSZKkrmbSJEmSJEk1TJokSZIkqYZJkyRJkiTVaPfT83qDvwIoSZIkTVheaZIkSZKkGiZNkiRJklTDpEmSJEmSapg0SZIkSVINkyZJkiRJqmHSJEmSJEk1TJokSZIkqYZJkyRJkiTVMGmSJEmSpBprd7oCPSNizeXMztRDkiRJ0qjySpMkSZIk1TBpkiRJkqQaJk2SJEmSVMOkSZIkSZJqmDRJkiRJUg2TJkmSJEmqYdIkSZIkSTVMmiRJkiSphkmTJEmSJNUwaZIkSZKkGiZNkiRJklTDpEmSNGFFxG0R8duIWBQRC0rZZhFxaUQsKX83LeUREadExNKIuD4iZjYcZ07ZfklEzOlUeyRJ7WHSJEma6F6fmTMyc1ZZPgG4PDOnAZeXZYBDgGllOg44FaokC5gL7AXsCcztS7QkSb2hrUmTPXiSpC40G5hf5ucDhzeUn52VK4FNImIr4CDg0sxcmZkPAJcCB491pSVJ7TMWV5rswZMkjVcJXBIR10TEcaVsy8y8u8zfA2xZ5rcB7mzYd1kpa1YuSeoRnRieZw+eJGm8eE1mzqTquDs+Il7XuDIzkyqxGrGIOC4iFkTEguXLl4/GISVJY6TdSZM9eJKkcSsz7yp/7wMupBrRcG/ptKP8va9sfhewbcPuU0pZs/L+r3V6Zs7KzFmTJ08e7aZIktqo3UmTPXiSpHEpIl4cERv1zQMHAjcAFwF998/OAb5f5i8C3l3uwd0beKh0Av4EODAiNi3Dxw8sZZKkHrF2Ow/e2IMXEWv04GXm3UPowduvX/kVA7zW6cDpALNmzRqVREyS1NO2BC6MCKji4bcy8z8j4mrgvIg4GrgdOLJsfzFwKLAUeBx4L0BmroyITwNXl+0+lZkrx64ZkqR2a1vSVHrtXpSZjzT04H2K53vwTuaFPXgfjIhzqB768FBJrH4CfLbh4Q8HAie2q96SpIkhM28BdhugfAXwhgHKEzi+ybHOAs4a7TpKksaHdl5psgdPkiRJUtdrW9JkD54kSZKkXtCJR45LkiRJUtdo64MgJEnS+FSNnq+kj0+SpFpeaZIkSZKkGiZNkiRJklTDpEmSJEmSapg0SZIkSVINHwQxFrzbVpIkSepaXmmSJEmSpBomTZIkSZJUw6RJkiRJkmqYNEmSJElSDZMmSZIkSaph0iRJkiRJNUyaJEmSJKmGSZMkSZIk1TBpkiRJkqQaJk2SJEmSVGPtTlegZ0V0ugaSJEmSRoFXmiRJkiSphkmTJEmSJNUwaZIkSZKkGiZNkiRJklSjpaQpInZtd0UkSRou45QkqZ1avdL0bxFxVUT8VURs3NYaSZI0dMYpSVLbtJQ0ZeZrgXcC2wLXRMS3IuKAttZMkqQWGackSe3U8j1NmbkE+DjwMeB/AadExO8i4i3tqpwkSa0yTkmS2qXVe5qmR8QXgZuA/YE3Z+aryvwX21g/SZIGZZySJLVTq1ea/hVYCOyWmcdn5kKAzPwjVa+eJEmdNOw4FRFrRcS1EfHDsrx9RPwmIpZGxLkRsW4pX68sLy3rpzYc48RS/vuIOKhNbZQkdUirSdOfAt/KzCcAIuJFEbEBQGZ+o12VkySpRSOJUx+iukLV53PAFzPzFcADwNGl/GjggVL+xbIdEbETcBSwM3Aw1UMp1hqVVkmSxoVWk6bLgPUbljcoZYOyB0+SNAaGFaciYgpVwvXvZTmohvRdUDaZDxxe5meXZcr6N5TtZwPnZOZTmXkrsBTYc0StkSSNK60mTZMy89G+hTK/QYv72oMnSWq34capfwH+HniuLG8OPJiZq8ryMmCbMr8NcGc5/irgobL96vIB9pEk9YBWk6bHImJm30JEvBp4YrCd7MGTJI2RIcepiHgTcF9mXtPuypXXOy4iFkTEguXLl4/FS0qSRsnaLW73YeD8iPgjEMBLgbe3sF9fD95GZbnlHryIaOzBu7LhmAP24EXEccBxAC972ctabJYkqUcMJ07tCxwWEYcCk4CXAF8CNomItUusmgLcVba/i+p3oJZFxNrAxsCKhvI+jfuslpmnA6cDzJo1K4fTSElSZ7T647ZXA68EPgD8JfCqwXrmxroHLzNPz8xZmTlr8uTJY/GSkqRxYjhxKjNPzMwpmTmVahj4TzPzncDPgLeVzeYA3y/zF5VlyvqfZmaW8qPKvbnbA9OAq0atcZKkjmv1ShPAHsDUss/MiCAzz67Zfkx78CRJE95Q41QzHwPOiYjPANcCZ5byM4FvRMRSYCVVokVm3hgR5wGLgVXA8Zn57IhaIkkaV1pKmiLiG8DLgUVAXyBIoGkwyswTgRPL/vsBH83Md0bE+VQ9dOcwcA/er+SvoLMAABXQSURBVGnowYuIi4BvRcQXgK2xB0+S1M9w4lSjzLwCuKLM38IA985m5pPAEU32Pwk4aYjVliR1iVavNM0CdirDEEbKHjxJ0mgbzTglSdIaWk2abqC6qfbu4byIPXiSpDYbUZySJKlOq0nTFsDiiLgKeKqvMDMPa0utJEkaGuOUJKltWk2a5rWzEpIkjdC8TldAktS7WkqaMvO/ImI7YFpmXhYRGwBrtbdqkiS1xjglSWqnln6nKSKOBS4AvlqKtgG+165KSZI0FBM9TkU8P3Vif0nqdS0lTcDxVL+79DBAZi4B/ke7KiVJ0hAZpyRJbdNq0vRUZj7dt1B+fNbHukqSxgvjlCSpbVpNmv4rIv4BWD8iDgDOB37QvmpJkjQkxilJUtu0mjSdACwHfgu8H7gY+Hi7KiVJ0hAZpyRJbdPq0/OeA84okyRJ44pxSpLUTi0lTRFxKwOMDc/MHUa9RpIkDZFxSpLUTq3+uO2shvlJwBHAZqNfHUmShsU4JUlqm5buacrMFQ3TXZn5L8CftrlukiS1xDglSWqnVofnzWxYfBFVj16rV6kkSWor45QkqZ1aDSj/3DC/CrgNOHLUayNJ0vAYpyRJbdPq0/Ne3+6KSJI0XMYpSVI7tTo87yN16zPzC6NTHUmShs44JUlqp6E8PW8P4KKy/GbgKmBJOyolSdIQGadGScTz8/mCh7hL0sTUatI0BZiZmY8ARMQ84EeZ+RftqpgkSUNgnJIktU1LjxwHtgSeblh+upRJkjQeGKckSW3T6pWms4GrIuLCsnw4ML89VZIkaciMU5Kktmn16XknRcSPgdeWovdm5rXtq5YkSa0zTkmS2qnV4XkAGwAPZ+aXgGURsX2b6iRJ0nAYpyRJbdFS0hQRc4GPASeWonWA/2hXpSRJGgrjlCSpnVq90vRnwGHAYwCZ+Udgo3ZVSpKkITJOSZLaptWk6enMTCABIuLF7auSJElDZpySJLVNq0nTeRHxVWCTiDgWuAw4o33VkiRpSIxTkqS2GfTpeRERwLnAK4GHgR2BT2TmpW2umyRJgzJOSZLabdCkKTMzIi7OzF0BA5AkaVwZbpyKiEnAz4H1qOLhBZk5tzx17xxgc+Aa4F2Z+XRErEf1e1CvBlYAb8/M28qxTgSOBp4F/iYzfzJqDZQkdVyrw/MWRsQeQzlwREyKiKsi4rqIuDEiPlnKt4+I30TE0og4NyLWLeXrleWlZf3UhmOdWMp/HxEHDaUekqQJYchxCngK2D8zdwNmAAdHxN7A54AvZuYrgAeokiHK3wdK+RfLdkTETsBRwM7AwcC/RcRaI22QJGn8aDVp2gu4MiL+EBHXR8RvI+L6QfYxGEmSxsqQ41RWHi2L65Qpgf2BC0r5fODwMj+7LFPWv6EMDZwNnJOZT2XmrcBSYM/RapgkqfNqh+dFxMsy8w5gyFd3ylOMmgWjPy/l84F5wKlUQWdeKb8A+HL/YATcGhF9wejXQ62TJKm3jCROlf3XohqC9wrgK8AfgAczc1XZZBmwTZnfBrgTIDNXRcRDVEP4tgGubDhs4z6SpB4w2JWm7wFk5u3AFzLz9sZpsINHxFoRsQi4j2qcecvBCGgMRnc2HNZgJEnqM6I4lZnPZuYMYApVh9wr21XRiDguIhZExILly5e362UkSW0wWNIUDfM7DPXgBiNJUpuNKE71ycwHgZ8B+1A9trxvJMYU4K4yfxewLUBZvzHVAyFWlw+wT+NrnJ6ZszJz1uTJk4dbVUlSBwyWNGWT+SExGEmS2mTYcSoiJkfEJmV+feAA4CaqePW2stkc4Ptl/qKyTFn/0zIU/SLgqPJAo+2BacBVw2iLJGmcGixp2i0iHo6IR4DpZf7hiHgkIh6u29FgJEkaA8OOU8BWwM/KAyOuBi7NzB8CHwM+Uu6h3Rw4s2x/JrB5Kf8IcAJAZt4InAcsBv4TOD4znx3ldkqSOqj2QRCZOZKn1G0FzC832b4IOC8zfxgRi4FzIuIzwLWsGYy+UYLRSqon5pGZN0ZEXzBahcFIklSMJE5l5vXA7gOU38IAT7/LzCeBI5oc6yTgpOHWRZI0vg3647bDZTCSJEmS1Ata/Z0mSZIkSZqQTJokSZIkqYZJkyRJkiTVMGmSJEmSpBptexCEmoiG32HMYf/0lSRJkqQx4pUmSZIkSaph0iRJkiRJNUyaJEmSJKmGSZMkSZIk1TBpkiRJkqQaJk2SJEmSVMOkSZIkSZJq+DtNA2n8LSVJkiRJE5pXmiRJkiSphkmTJEmSJNUwaZIkSZKkGiZNkiRJklTDpEmSJEmSapg0SZIkSVINkyZJkiRJquHvNEmSpJY0/oxhZufqIUljzStNkiRJklTDpEmSJEmSajg8r5MaxzmAYx0kSZKkccgrTZIkSZJUw6RJkiRJkmqYNEmSJElSDZMmSZIkSarRtqQpIraNiJ9FxOKIuDEiPlTKN4uISyNiSfm7aSmPiDglIpZGxPURMbPhWHPK9ksiYk676ixJmjiMU5KkVrXzStMq4G8zcydgb+D4iNgJOAG4PDOnAZeXZYBDgGllOg44FargBcwF9gL2BOb2BTBJkkbAOCVJaknbkqbMvDszF5b5R4CbgG2A2cD8stl84PAyPxs4OytXAptExFbAQcClmbkyMx8ALgUOble9JUkTg3FKktSqMbmnKSKmArsDvwG2zMy7y6p7gC3L/DbAnQ27LStlzcolSRoVYxGnIuK4iFgQEQuWL18+qvWXJLVX25OmiNgQ+A7w4cx8uHFdZiYwKr/oajCSJA3HWMWpzDw9M2dl5qzJkyePxiElSWOkrUlTRKxDFYi+mZnfLcX3luEMlL/3lfK7gG0bdp9SypqVr8FgJEkaqrGMU70m4vlJknpdO5+eF8CZwE2Z+YWGVRcBfU8WmgN8v6H83eXpRHsDD5XhET8BDoyITcuNtQeWMkmShs04JUlq1dptPPa+wLuA30bEolL2D8DJwHkRcTRwO3BkWXcxcCiwFHgceC9AZq6MiE8DV5ftPpWZK9tYb0nSxGCckiS1JKrh2r1l1qxZuWDBguEfoFNjDXrwXEiauCLimsyc1el6jEcjjlP9tCts9Q9LzV7H8CWpW7Uaq9p5pUmSJHUx71eSpMqYPHJckiRJkrqVV5rGk8YuPcc6SJIkSeOCV5okSZIkqYZJkyRJkiTVMGmSJEmSpBomTZIkSZJUwwdBSJKkEfE5RpJ6nVeaJEmSJKmGSZMkSZIk1TBpkiRJkqQaJk2SJEmSVMMHQYxX3lUrSZIkjQteaZIkSZKkGiZNkiRJklTDpEmSJEmSapg0SZIkSVINkyZJkiRJqmHSJEmSJEk1TJokSZIkqYa/09Rt/P0mSdI41himwFAlqTd4pUmSJEmSapg0SZIkSVINkyZJkiRJquE9Td2g/wBxSdKEZ2iQpLHjlSZJkiRJquGVJkmS1DY+9FVSL/BKkyRJkiTVMGmSJE1IEXFWRNwXETc0lG0WEZdGxJLyd9NSHhFxSkQsjYjrI2Jmwz5zyvZLImJOJ9oiSWqvtiVNBiNJ0jj3deDgfmUnAJdn5jTg8rIMcAgwrUzHAadCFdeAucBewJ7A3L7YJknqHe280vR1DEaSpHEqM38OrOxXPBuYX+bnA4c3lJ+dlSuBTSJiK+Ag4NLMXJmZDwCX8sLYJ0nqcm1LmgxGkqQutGVm3l3m7wG2LPPbAHc2bLeslDUrlyT1kLG+p6ltwSgijouIBRGxYPny5aNba0nShJOZCYza896MU5LUvTr2IIjRDkaZeXpmzsrMWZMnTx6tw0qSJpZ7y0gHyt/7SvldwLYN200pZc3KX8A4JUnda6yTprYFI0mSRsFFQN9Dh+YA328of3d5cNHewENl5MRPgAMjYtNyz+2BpUyS1EPGOmkyGEmSxoWI+Dbwa2DHiFgWEUcDJwMHRMQS4I1lGeBi4BZgKXAG8FcAmbkS+DRwdZk+VcokST1k7XYduASj/YAtImIZ1VPwTgbOK4HpduDIsvnFwKFUwehx4L1QBaOI6AtGYDCSJI2SzHxHk1VvGGDbBI5vcpyzgLNGsWo9K+L5+Ry1AfqS1H5tS5oMRpIkSZJ6QcceBCFJkiRJ3cCkSZIkSZJqmDRJkiRJUo223dMkSZLUjA+FkNRNTJq6WWPEAaOOJEmS1AYOz5MkSZKkGiZNkiRJklTDpEmSJEmSanhPUy/xrlpJkiRp1HmlSZIkSZJqmDRJkiRJUg2TJkmSJEmqYdIkSZIkSTV8EIQkSRo3/N12SeORSVOv8kl6kiRJ0qhweJ4kSZIk1fBKkyRJ6qj+Q/KarXPghKRO8UqTJEmSJNXwStNEYDedJKkHGM4kdYpJ00TjY4kkSZKkITFpmujstpMkdSHDl6Sx5D1NkiRJklTDK02SJKmrOfJcUrt5pUmSJEmSapg0SZIkSVINh+fpec1+XdBxDpKkLuJDIiSNNpMmDc7oI0nqUs1CmPdBSRoKh+dJkiRJUo2uSZoi4uCI+H1ELI2IEzpdnwkrovnUbDtJmgCMU93NsCWpTlckTRGxFvAV4BBgJ+AdEbFTZ2ulF2glgTIaSepBxqnu0GooqusfNJRJE1NXJE3AnsDSzLwlM58GzgFmd7hOGq7hRCAjlaTxzTg1wbSSWJloSb2jWx4EsQ1wZ8PyMmCvDtVF7dJqRBnNyNPqXcE+WVBSPeOUBtXOxKmVkFW3T6O6/Zu9juFQva5bkqZBRcRxwHFl8dGI+P0Qdt8CuH/0a9URvdQWaHd76iJDK1FnaBGwl86NbRmfxltbtut0BcaTEcYpGH/nd7TZvhEYTkI2mvtEeP663ERuX0uxqluSpruAbRuWp5Sy1TLzdOD04Rw8IhZk5qzhV2/86KW2QG+1x7aMT7ZFo6StcQp6//zavu5m+7qb7Rtct9zTdDUwLSK2j4h1gaOAizpcJ0mS+hinJKmHdcWVpsxcFREfBH4CrAWclZk3drhakiQBxilJ6nVdkTQBZObFwMVtOvywh0uMQ73UFuit9tiW8cm2aFS0OU5B759f29fdbF93s32DiPRxJ5IkSZLUVLfc0yRJkiRJHTHhk6aIODgifh8RSyPihE7XZ6gi4raI+G1ELIqIBaVss4i4NCKWlL+bdrqeA4mIsyLivoi4oaFswLpH5ZRynq6PiJmdq/kLNWnLvIi4q5ybRRFxaMO6E0tbfh8RB3Wm1gOLiG0j4mcRsTgiboyID5Xyrjs3NW3punMTEZMi4qqIuK605ZOlfPuI+E2p87nlIQRExHpleWlZP7WT9dfIdHusGkg3x6+B9FJMG0gvxbmB9FLsG0gvxcOBjEmMzMwJO1HdrPsHYAdgXeA6YKdO12uIbbgN2KJf2f8FTijzJwCf63Q9m9T9dcBM4IbB6g4cCvwYCGBv4Dedrn8LbZkHfHSAbXcqn7X1gO3LZ3CtTrehoX5bATPL/EbAzaXOXXduatrSdeemvL8blvl1gN+U9/s84KhSfhrwgTL/V8BpZf4o4NxOt8Fp2Oe+62NVk3Z1bfxq0p6eiWlDaF/XfZfWtK9nYt8Q29cT53AsYuREv9K0J7A0M2/JzKeBc4DZHa7TaJgNzC/z84HDO1iXpjLz58DKfsXN6j4bODsrVwKbRMRWY1PTwTVpSzOzgXMy86nMvBVYSvVZHBcy8+7MXFjmHwFuArahC89NTVuaGbfnpry/j5bFdcqUwP7ABaW8/3npO18XAG+IGM5PWWoc6NVYNZCuiF8D6aWYNpBeinMD6aXYN5BeiocDGYsYOdGTpm2AOxuWl1H/ARqPErgkIq6J6tfmAbbMzLvL/D3Alp2p2rA0q3u3nqsPlsv2ZzUMM+matpTL1btT9dh09bnp1xbownMTEWtFxCLgPuBSqp6/BzNzVdmksb6r21LWPwRsPrY11igZ15/LEei1+DWQrv7ebFHXfZcOppdi30B6IR4OpN0xcqInTb3gNZk5EzgEOD4iXte4Mqvrjl35iMRurntxKvByYAZwN/DPna3O0ETEhsB3gA9n5sON67rt3AzQlq48N5n5bGbOAKZQ9fi9ssNVkkaiZ+PXQHqtPUVXfpfW6aXYN5BeiYcDaXeMnOhJ013Atg3LU0pZ18jMu8rf+4ALqT4k9/ZdIi5/7+tcDYesWd277lxl5r3lH/BzwBk8f1l73LclItah+lL9ZmZ+txR35bkZqC3dfG4AMvNB4GfAPlRDQvp+c6+xvqvbUtZvDKwY46pqdHTF53KoejB+DaQrvzdb1e3fpf31UuwbSC/Gw4G0K0ZO9KTpamBaebLGulQ3gl3U4Tq1LCJeHBEb9c0DBwI3ULVhTtlsDvD9ztRwWJrV/SLg3eVpNXsDDzVcLh+X+o1t/jOqcwNVW44qT27ZHpgGXDXW9WumjOk9E7gpM7/QsKrrzk2ztnTjuYmIyRGxSZlfHziAakz6z4C3lc36n5e+8/U24Kell1Tdp6tj1UB6NH4NpOu+N4eiG79Lm+ml2DeQXoqHAxmTGNn/yRATbaJ6+snNVOMe/7HT9Rli3XegerLJdcCNffWnGpN5ObAEuAzYrNN1bVL/b1NdCn6Gapzp0c3qTvVUlK+U8/RbYFan699CW75R6np9+ce5VcP2/1ja8nvgkE7Xv19bXkM1/OB6YFGZDu3Gc1PTlq47N8B04NpS5xuAT5TyHagC2VLgfGC9Uj6pLC8t63fodBucRnT+uzZWNWlPV8evJm3qmZg2hPZ13XdpTft6JvYNsX09cQ7HIkZG2VGSJEmSNICJPjxPkiRJkmqZNEmSJElSDZMmSZIkSaph0iRJkiRJNUyaJEmSJKmGSZPUJhHxaJuP/+GI2GCsXk+S1FuMU1LrTJqk7vVhYINBt5IkqTOMU+oZa3e6AtJEEhEvp/oxvMnA48Cxmfm7iPg68DAwC3gp8PeZeUFEvAj4MrA/cCfVjwqeBWxdpp9FxP2Z+fpy/JOANwFPALMz896xbJ8kqbsZp6SBeaVJGlunA3+dma8GPgr8W8O6rah+sftNwMml7C3AVGAn4F3APgCZeQrwR+D1fYEIeDFwZWbuBvwcOLatLZEk9SLjlDQArzRJYyQiNgT+J3B+RPQVr9ewyfcy8zlgcURsWcpeA5xfyu+JiJ/VvMTTwA/L/DXAAaNWeUlSzzNOSc2ZNElj50XAg5k5o8n6pxrmo8k2dZ7JzCzzz+K/b0nS0BinpCYcnieNkcx8GLg1Io4AiMpug+z2K+CtEfGi0qu3X8O6R4CN2lJZSdKEY5ySmjNpktpng4hY1jB9BHgncHREXAfcCMwe5BjfAZYBi4H/ABYCD5V1pwP/OchQCEmSmjFOSS2K56+SShqPImLDzHw0IjYHrgL2zcx7Ol0vSZLAOKWJwbGk0vj3w4jYBFgX+LSBSJI0zhin1PO80iRJkiRJNbynSZIkSZJqmDRJkiRJUg2TJkmSJEmqYdIkSZIkSTVMmiRJkiSphkmTJEmSJNX4/34Odjv6Uz3kAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 128"
      ],
      "metadata": {
        "id": "YZy7fmA-ku9b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_dataset(dataset):\n",
        "  new_dataset = []\n",
        "\n",
        "  for pt_data, en_data in dataset.batch(1):\n",
        "    en_tokens = en_tokenizer.tokenize(en_data).numpy()[0]\n",
        "    pt_tokens = pt_tokenizer.tokenize(pt_data).numpy()[0]\n",
        "\n",
        "    if len(en_tokens) > MAX_LENGTH or len(pt_tokens) > MAX_LENGTH:continue\n",
        "\n",
        "    en_tokens = np.concatenate([en_tokens, np.zeros(MAX_LENGTH - len(en_tokens), np.int64)])\n",
        "    pt_tokens = np.concatenate([pt_tokens, np.zeros(MAX_LENGTH - len(pt_tokens), np.int64)])\n",
        "\n",
        "    new_dataset.append({\"en\": en_tokens, \"pt\": pt_tokens})\n",
        "\n",
        "  new_dataset = pd.DataFrame(new_dataset)  \n",
        "  return new_dataset"
      ],
      "metadata": {
        "id": "m2J4RFXTJlwn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_dataset = pad_dataset(train_dataset)"
      ],
      "metadata": {
        "id": "C6sYb-BGLifS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "43e7ffba-55c7-4f6e-f31d-a9b680fdea02"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fb4ca2849213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-5e57c0d43db8>\u001b[0m in \u001b[0;36mpad_dataset\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpt_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0men_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpt_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_dataset.iloc[:10]"
      ],
      "metadata": {
        "id": "NDWcpKB-3eT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_max_tokens(pt, en):\n",
        "  num_tokens = tf.maximum(tf.shape(pt)[1],tf.shape(en)[1])\n",
        "  return num_tokens < MAX_LENGTH"
      ],
      "metadata": {
        "id": "cvLNtGH42-3H"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_pairs(pt, en):\n",
        "    pt = tokenizers.pt.tokenize(pt)\n",
        "    pt = pt.to_tensor()\n",
        "\n",
        "    en = tokenizers.en.tokenize(en)\n",
        "    en = en.to_tensor()\n",
        "    return pt, en"
      ],
      "metadata": {
        "id": "Q0RMW6z24LGS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "kuSagYWs4OTk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .cache()\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .filter(filter_max_tokens)\n",
        "      .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "\n",
        "train_batches = make_batches(train_dataset)\n",
        "valid_batches = make_batches(valid_dataset)"
      ],
      "metadata": {
        "id": "mzmhuXbP4QYM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Encoding"
      ],
      "metadata": {
        "id": "NfZYpJ02EG2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  encoding = np.zeros(d_model)\n",
        "\n",
        "  for j in range(d_model):\n",
        "    i = j//2\n",
        "    angle = position/(10000**(2*i/d_model))\n",
        "\n",
        "    if j%2==0:\n",
        "      encoding[j] = np.sin(angle)\n",
        "    else:\n",
        "      encoding[j] = np.cos(angle)\n",
        "\n",
        "  return encoding"
      ],
      "metadata": {
        "id": "0YWPsZtD-zoK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positional_encoding_list = []\n",
        "d_model = 128\n",
        "\n",
        "for position in range(MAX_LENGTH):\n",
        "  positional_encoding_list.append(positional_encoding(position, d_model))\n",
        "\n",
        "positional_encoding_tensor = K.constant(positional_encoding_list)"
      ],
      "metadata": {
        "id": "5dMFWg8dDTY2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking"
      ],
      "metadata": {
        "id": "1v7p7T4kf8C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "Dpp-PYzioCt2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    n = int(size * (size+1) / 2)\n",
        "    mask = tfp.math.fill_triangular(tf.ones((n,), dtype=tf.float32), upper=False)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "GRlvxZNJnzaI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer FeedForward"
      ],
      "metadata": {
        "id": "gS3pY3IQNHsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerFeedForward(keras.Model):\n",
        "  def __init__(self, d_feedforward, d_model):\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = Sequential([\n",
        "                             Dense(d_feedforward, activation=\"relu\"),\n",
        "                             Dense(d_model)\n",
        "\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return self.model.call(inputs)"
      ],
      "metadata": {
        "id": "KHV-vDBtNL2s"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder Block"
      ],
      "metadata": {
        "id": "XpDvgLz8LE2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(Layer):\n",
        "  def __init__(self, d_model, number_heads, d_feedforward):\n",
        "    super().__init__()\n",
        "    self.multi_head_attention = MultiHeadAttention(num_heads=number_heads, key_dim=d_model)\n",
        "\n",
        "    self.feedforward = TransformerFeedForward(d_feedforward=d_feedforward, d_model=d_model)\n",
        "\n",
        "    self.normal_1 = LayerNormalization(epsilon=1e-6)\n",
        "    self.normal_2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "  def call(self, x, mask):\n",
        "    attention_output = self.multi_head_attention(x, x, x, mask)\n",
        "\n",
        "    normal_output = self.normal_1(attention_output + x)\n",
        "\n",
        "    feedforward_output = self.feedforward(normal_output)\n",
        "\n",
        "    output = self.normal_2(feedforward_output + x) \n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "7z0eecFKDW8o"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder Block"
      ],
      "metadata": {
        "id": "MQuKbs7kRbAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(Layer):\n",
        "  def __init__(self, number_heads, d_feedforward, d_model):\n",
        "    super().__init__()\n",
        "    self.multi_head_attention_1 = MultiHeadAttention(num_heads=number_heads, key_dim=d_model)\n",
        "    self.multi_head_attention_2 = MultiHeadAttention(num_heads=number_heads, key_dim=d_model)\n",
        "    \n",
        "    self.feedforward = TransformerFeedForward(d_feedforward=d_feedforward, d_model=d_model)\n",
        "\n",
        "    self.normal_1 = LayerNormalization(epsilon=1e-6)\n",
        "    self.normal_2 = LayerNormalization(epsilon=1e-6)\n",
        "    self.normal_3 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "  def call(self, x, encoder_output, look_ahead_mask, padding_mask):    \n",
        "    attention_output_1, attention_weights_1 = self.multi_head_attention_1(\n",
        "        x, x, x, look_ahead_mask, return_attention_scores=True)\n",
        "\n",
        "    normal_output_1 = self.normal_1(attention_output_1 + x)\n",
        "    \n",
        "    attention_output_2, attention_weights_2 = self.multi_head_attention_2(\n",
        "        encoder_output, encoder_output, normal_output_1, padding_mask, return_attention_scores=True)\n",
        "\n",
        "    normal_output_2 = self.normal_2(attention_output_2 + normal_output_1)\n",
        "\n",
        "    feedforward_output = self.feedforward(normal_output_2)\n",
        "\n",
        "    normal_output_3 = self.normal_3(feedforward_output + normal_output_2)\n",
        "\n",
        "    return normal_output_3, attention_weights_1, attention_weights_2"
      ],
      "metadata": {
        "id": "1B5daDzvRb0G"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "lHLbw92Z-39h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Layer):\n",
        "  def __init__(self, number_blocks, d_feedforward, d_model, source_vocab_size,\n",
        "               number_heads, positional_encoding_tensor):\n",
        "    super().__init__()\n",
        "    self.positional_encoding_tensor = positional_encoding_tensor\n",
        "\n",
        "    self.embedding = Embedding(source_vocab_size, d_model)\n",
        "\n",
        "    self.number_blocks = number_blocks\n",
        "\n",
        "    self.d_model = d_model\n",
        "\n",
        "    self.encoder_blocks = []\n",
        "\n",
        "    for _ in range(number_blocks):\n",
        "      self.encoder_blocks.append(EncoderBlock(d_model=d_model, number_heads=number_heads, d_feedforward=d_feedforward))\n",
        "\n",
        "  def call(self, x, mask):\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    \n",
        "    pe = self.positional_encoding_tensor[:x.shape[1], :]\n",
        "\n",
        "    pe = tf.repeat(tf.expand_dims(pe, axis=0), axis=0, repeats=x.shape[0])\n",
        "\n",
        "    x += pe\n",
        "\n",
        "    for i in range(self.number_blocks):\n",
        "      x = self.encoder_blocks[i](x, mask)\n",
        "\n",
        "    return x "
      ],
      "metadata": {
        "id": "fq4n4Cdx-8OU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "4wQHaQXw-64q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Layer):\n",
        "  def __init__(self, number_blocks, d_feedforward, d_model, number_heads,\n",
        "               target_vocab_size, positional_encoding_tensor):\n",
        "    super().__init__()\n",
        "    self.positional_encoding_tensor = positional_encoding_tensor\n",
        "\n",
        "    self.embedding = Embedding(target_vocab_size, d_model)\n",
        "\n",
        "    self.number_blocks = number_blocks\n",
        "    \n",
        "    self.d_model = d_model\n",
        "\n",
        "    self.decoder_blocks = []\n",
        "\n",
        "    for _ in range(number_blocks):\n",
        "      self.decoder_blocks.append(DecoderBlock(d_model=d_model, number_heads=number_heads, d_feedforward=d_feedforward))\n",
        "\n",
        "  def call(self, x, encoder_output, look_ahead_mask, padding_mask):\n",
        "      attention_weights = []\n",
        "\n",
        "      x = self.embedding(x)\n",
        "      x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "\n",
        "      pe = self.positional_encoding_tensor[:x.shape[1], :]\n",
        "      pe = tf.repeat(tf.expand_dims(pe, axis=0), axis=0, repeats=x.shape[0])\n",
        "      x += pe\n",
        "\n",
        "      for i in range(self.number_blocks):\n",
        "        x, attention_weight_1, attention_weight_2 = self.decoder_blocks[i](x=x,\n",
        "                                                           encoder_output=encoder_output,\n",
        "                                                           look_ahead_mask=look_ahead_mask,\n",
        "                                                           padding_mask=padding_mask)\n",
        "\n",
        "        attention_weights.append({\"1\":attention_weight_1, \"2\":attention_weight_2})\n",
        "\n",
        "      return x, attention_weights      \n"
      ],
      "metadata": {
        "id": "yRw8km7WCc0L"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "SurL2AVE-Czp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(keras.Model):\n",
        "  def __init__(self, number_encoder_blocks, number_decoder_blocks, number_heads,\n",
        "               d_feedforward, d_model, source_vocab_size,\n",
        "               target_vocab_size, positional_encoding_tensor):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = Encoder(number_blocks=number_encoder_blocks,\n",
        "                           d_feedforward=d_feedforward, d_model=d_model,\n",
        "                           source_vocab_size=source_vocab_size,\n",
        "                           number_heads=number_heads,\n",
        "                           positional_encoding_tensor=positional_encoding_tensor) \n",
        "\n",
        "    self.decoder = Decoder(number_blocks=number_decoder_blocks,\n",
        "                           d_feedforward=d_feedforward, d_model=d_model,\n",
        "                           number_heads=number_heads,\n",
        "                           target_vocab_size=target_vocab_size,\n",
        "                           positional_encoding_tensor=positional_encoding_tensor)\n",
        "\n",
        "    self.last_layer = Dense(target_vocab_size)\n",
        "\n",
        "  def create_masks(self, pt_inputs, en_inputs):\n",
        "    padding_mask = create_padding_mask(pt_inputs)\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(en_inputs)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(en_inputs)\n",
        "    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "    return padding_mask, look_ahead_mask\n",
        "\n",
        "  def call(self, inputs):\n",
        "    pt_inputs, en_inputs = inputs\n",
        "\n",
        "    padding_mask, look_ahead_mask = self.create_masks(pt_inputs, en_inputs)\n",
        "\n",
        "    encoder_output = self.encoder(pt_inputs, padding_mask)\n",
        "\n",
        "    decoder_output, attention_weights = self.decoder(\n",
        "        en_inputs, encoder_output, look_ahead_mask, padding_mask)\n",
        "\n",
        "    final_output = self.last_layer(decoder_output)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "metadata": {
        "id": "H6-6TJjP-Acj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "RydZEd08quDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_blocks = 4\n",
        "d_model = 128\n",
        "d_feedforward = 512\n",
        "number_heads = 8"
      ],
      "metadata": {
        "id": "3GFJejbtqP1Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "qbl67v7VrMUr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "metadata": {
        "id": "PrHpz4aErTq8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "metadata": {
        "id": "062f9IzirbBA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "VUdF7wmrreWt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "metadata": {
        "id": "Q0E3ahclrfvI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(number_encoder_blocks=number_blocks,\n",
        "                          number_decoder_blocks=number_blocks,\n",
        "                          number_heads=number_heads,\n",
        "                          d_feedforward=d_feedforward, d_model=d_model,\n",
        "                          source_vocab_size=pt_tokenizer.get_vocab_size().numpy(),\n",
        "                          target_vocab_size=en_tokenizer.get_vocab_size().numpy(),\n",
        "                          positional_encoding_tensor=positional_encoding_tensor)"
      ],
      "metadata": {
        "id": "rGrid86Trhp5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_step_signature = [\n",
        "#     tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "#     tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "# ]\n",
        "\n",
        "# @tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer([inp, tar_inp])\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "metadata": {
        "id": "pxvnM_cFuSlp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "for epoch in range(5):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "    inp = tf.pad(tensor=inp, paddings=tf.constant([[0, 0], [0, MAX_LENGTH-inp.shape[1]]]))\n",
        "    tar = tf.pad(tensor=tar, paddings=tf.constant([[0, 0], [0, MAX_LENGTH-tar.shape[1]+1]]))\n",
        "\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 5 == 0:\n",
        "      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10bKnpxasPVm",
        "outputId": "d3cc0442-14ab-4220-9f79-8fa3ec9d3654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 8.8526 Accuracy 0.0000\n",
            "Epoch 1 Batch 5 Loss 8.8582 Accuracy 0.0001\n",
            "Epoch 1 Batch 10 Loss 8.8568 Accuracy 0.0001\n",
            "Epoch 1 Batch 15 Loss 8.8527 Accuracy 0.0000\n",
            "Epoch 1 Batch 20 Loss 8.8481 Accuracy 0.0000\n",
            "Epoch 1 Batch 25 Loss 8.8398 Accuracy 0.0000\n",
            "Epoch 1 Batch 30 Loss 8.8293 Accuracy 0.0010\n",
            "Epoch 1 Batch 35 Loss 8.8189 Accuracy 0.0026\n",
            "Epoch 1 Batch 40 Loss 8.8076 Accuracy 0.0059\n",
            "Epoch 1 Batch 45 Loss 8.7966 Accuracy 0.0098\n",
            "Epoch 1 Batch 50 Loss 8.7849 Accuracy 0.0131\n",
            "Epoch 1 Batch 55 Loss 8.7729 Accuracy 0.0160\n",
            "Epoch 1 Batch 60 Loss 8.7604 Accuracy 0.0187\n",
            "Epoch 1 Batch 65 Loss 8.7489 Accuracy 0.0208\n",
            "Epoch 1 Batch 70 Loss 8.7373 Accuracy 0.0224\n",
            "Epoch 1 Batch 75 Loss 8.7260 Accuracy 0.0239\n",
            "Epoch 1 Batch 80 Loss 8.7153 Accuracy 0.0251\n",
            "Epoch 1 Batch 85 Loss 8.7038 Accuracy 0.0263\n",
            "Epoch 1 Batch 90 Loss 8.6925 Accuracy 0.0273\n",
            "Epoch 1 Batch 95 Loss 8.6810 Accuracy 0.0284\n",
            "Epoch 1 Batch 100 Loss 8.6695 Accuracy 0.0293\n",
            "Epoch 1 Batch 105 Loss 8.6584 Accuracy 0.0300\n",
            "Epoch 1 Batch 110 Loss 8.6464 Accuracy 0.0307\n",
            "Epoch 1 Batch 115 Loss 8.6349 Accuracy 0.0314\n",
            "Epoch 1 Batch 120 Loss 8.6230 Accuracy 0.0320\n",
            "Epoch 1 Batch 125 Loss 8.6108 Accuracy 0.0326\n",
            "Epoch 1 Batch 130 Loss 8.5989 Accuracy 0.0330\n",
            "Epoch 1 Batch 135 Loss 8.5862 Accuracy 0.0335\n",
            "Epoch 1 Batch 140 Loss 8.5736 Accuracy 0.0339\n",
            "Epoch 1 Batch 145 Loss 8.5608 Accuracy 0.0343\n",
            "Epoch 1 Batch 150 Loss 8.5476 Accuracy 0.0345\n",
            "Epoch 1 Batch 155 Loss 8.5342 Accuracy 0.0348\n",
            "Epoch 1 Batch 160 Loss 8.5201 Accuracy 0.0352\n",
            "Epoch 1 Batch 165 Loss 8.5058 Accuracy 0.0356\n",
            "Epoch 1 Batch 170 Loss 8.4909 Accuracy 0.0359\n",
            "Epoch 1 Batch 175 Loss 8.4764 Accuracy 0.0362\n",
            "Epoch 1 Batch 180 Loss 8.4611 Accuracy 0.0365\n",
            "Epoch 1 Batch 185 Loss 8.4454 Accuracy 0.0368\n",
            "Epoch 1 Batch 190 Loss 8.4299 Accuracy 0.0371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lv2XTQUq7ny3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}